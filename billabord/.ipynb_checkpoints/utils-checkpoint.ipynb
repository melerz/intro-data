{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import pdb\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import warnings\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import requests as req\n",
    "import re\n",
    "from imblearn.over_sampling import SMOTE\n",
    "# import bokeh\n",
    "# from bokeh.io import output_notebook, show\n",
    "# from bokeh.resources import INLINE\n",
    "# import bokeh.plotting as bp\n",
    "# from bokeh.plotting import figure\n",
    "#output_notebook(resources=INLINE)\n",
    "\n",
    "\n",
    "\n",
    "mpl.style.use('seaborn')\n",
    "mpl.rcParams['figure.figsize'] = [20,15]\n",
    "mpl.rcParams['axes.titlesize'] = 20\n",
    "mpl.rcParams['axes.labelsize'] = 16\n",
    "mpl.rcParams['xtick.labelsize'] =15\n",
    "mpl.rcParams['ytick.labelsize'] = 15\n",
    "mpl.rcParams['legend.fontsize'] = 15\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "\n",
    "PLT_WIDTH_INCH = 20\n",
    "PLT_HEIGHT_INCH = 15\n",
    "plt.rcParams['figure.figsize'] = [PLT_WIDTH_INCH, PLT_HEIGHT_INCH]\n",
    "\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%load_ext autoreload\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOAD DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#features correlation\n",
    "all_songs = pd.read_pickle('fixed_all_songs.dat')\n",
    "popular_songs = all_songs[all_songs['popular']==1]\n",
    "unpopular_songs = all_songs[all_songs['popular']==0]\n",
    "all_genres = list(pd.read_pickle('all_genres.dat')[0].values)\n",
    "GENRES = list(pd.read_pickle('spotify_genres.dat')[0].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CONSTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPOTIFY_COLUMNS = ['artist','artist_id','name','genre','decade','duration_ms','acousticness',\n",
    "                  'danceability','energy','id','year',\n",
    "                  'instrumentalness','liveness','loudness','speechiness','tempo','valence','popular']\n",
    "\n",
    "\n",
    "selected_columns=['duration_ms',\n",
    "                  'acousticness',\n",
    "                  'danceability',\n",
    "                  'energy',\n",
    "                  'instrumentalness',\n",
    "                  'liveness',\n",
    "                  'loudness',\n",
    "                  'speechiness',\n",
    "                  'tempo',\n",
    "                  'valence',\n",
    "                  'genre_id']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load spotify_client/spotify_client.py\n",
    "import spotipy\n",
    "import json\n",
    "from spotipy.oauth2 import SpotifyClientCredentials\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# getting credentials to request special API\n",
    "credenials = SpotifyClientCredentials(client_id=\"5659eaf41b194134866170761e2fb293\",client_secret=\"17e2a9fa37c2466baa2ba05752896cdc\")\n",
    "\n",
    "# getting the client\n",
    "spotify_client = spotipy.Spotify(client_credentials_manager=credenials)\n",
    "\n",
    "\"\"\"\n",
    "we will get all the features from spotify, by song name and artist name.\n",
    "this function will create a json file with all the data\n",
    "\"\"\"\n",
    "def get_song_features_and_info_json(song_name, artist_name):\n",
    "\n",
    "    # getting credentials to request special API\n",
    "    credenials = SpotifyClientCredentials(client_id=\"5659eaf41b194134866170761e2fb293\",client_secret=\"17e2a9fa37c2466baa2ba05752896cdc\")\n",
    "\n",
    "    # getting the client\n",
    "    spotify_client = spotipy.Spotify(client_credentials_manager=credenials)\n",
    "\n",
    "    # getting the song id in order to retrieve features, limiting to 1 since it sorts the results by popularity\n",
    "    song_results = spotify_client.search(q='artist:' + artist_name + ' track:' + song_name, type='track',limit=1)\n",
    "    #print(song_results)\n",
    "    tracks = song_results['tracks']['items']\n",
    "    if len(tracks)==0:\n",
    "        print(\"***no results for the requested track:{}***\".format(song_name+\":\"+artist_name))\n",
    "        return\n",
    "    result_dict = tracks[0]\n",
    "\n",
    "    # creating dict for track\n",
    "    song_dict = creating_song_dictionary(artist_name, result_dict, spotify_client)\n",
    "\n",
    "    return song_dict\n",
    "def creating_song_dictionary(artist_name, result_dict, spotify_client):\n",
    "    song_dict = {}\n",
    "    song_dict['artist'] = artist_name\n",
    "    song_id = [result_dict['uri']]\n",
    "    song_dict['uri'] = song_id\n",
    "    song_dict['year'] = result_dict['album']['release_date'][:4]\n",
    "    song_dict['artist_id'] = result_dict['artists'][0]['id']\n",
    "    song_dict['track_id'] = result_dict['id']\n",
    "    song_dict['name'] = spotify_client.track(song_dict['track_id'])['name']\n",
    "    song_dict['popularity'] = result_dict['popularity']\n",
    "    song_dict['preview_link'] = result_dict['preview_url']\n",
    "    features = spotify_client.audio_features(song_id)\n",
    "    song_dict['main_features'] = features[0]\n",
    "\n",
    "    return song_dict    \n",
    "    \n",
    "def get_artist_and_title(df):\n",
    "    #return [\"{}:{}\".format(tup[0],tup[1]) for tup in list(zip(zz.loc['artist'].values,zz.loc['title'].values))]\n",
    "    return list(zip(df.loc[:,'name'].values,df.loc[:,'artist'].values))\n",
    "\n",
    "\n",
    "\n",
    "def scale_features(data):\n",
    "    clmns = data.columns\n",
    "    scaler = StandardScaler(with_mean=True)\n",
    "    return pd.DataFrame(scaler.fit_transform(data),columns=clmns)\n",
    "\n",
    "\n",
    "def get_artist_genre(spotify_client,artist_id):\n",
    "    artist_data = spotify_client.artist(artist_id)\n",
    "    spotify_genres = artist_data[\"genres\"]\n",
    "    return spotify_genres\n",
    "\n",
    "def get_number_of_apearence(genre,spotify_genres):\n",
    "    count=0\n",
    "    for spot_genre in spotify_genres:\n",
    "        res = re.search(genre, spot_genre)\n",
    "        if res:\n",
    "            count+=1\n",
    "    return count\n",
    "\n",
    "def get_genres_scores_of_artist(spotify_client,artist_id):\n",
    "    artist_genres=get_artist_genre(spotify_client,artist_id)\n",
    "    return [get_number_of_apearence(genre,artist_genres) for genre in GENRES]\n",
    "\n",
    "def get_genre_of_artist(spotify_client,artist_id):\n",
    "    scores=get_genres_scores_of_artist(spotify_client,artist_id)\n",
    "    if np.sum(scores)==0:\n",
    "        return 'na'\n",
    "    return GENRES[np.argmax(scores)]\n",
    "\n",
    "\n",
    "\n",
    "def remove_dup_songs_from_random(all_songs_data_frame,subset):\n",
    "    res=all_songs_data_frame.drop_duplicates(subset = subset,keep = 'first',inplace = False)\n",
    "    return res\n",
    "\n",
    "\n",
    "def get_year(artist,title):\n",
    "    try:\n",
    "        res=req.get('https://api.discogs.com/database/search?artist={0}&release_title={1}&per_page=10&page=1&token=AVfnfICgSgXIDXAWivYivedRIhMcDRvYCxrIshPk'.format(artist,title))\n",
    "        return np.min([np.int(r['year']) for r in res.json()['results'] if 'year' in r.keys()]) \n",
    "    except Exception as e:\n",
    "        #print(e)\n",
    "        return None\n",
    "    \n",
    "def get_all_fixed_years(data):\n",
    "    years=[]\n",
    "    details=get_artist_and_title(data)\n",
    "    for name,artist in details:\n",
    "        year=get_year(artist,name)\n",
    "        years.append(year)\n",
    "        #print(year)\n",
    "    return years\n",
    "\n",
    "def extract_features_from_spotify(song_dict):\n",
    "    new_song_dict={}\n",
    "    for feature in SPOTIFY_COLUMNS:\n",
    "        val = song_dict.get(feature,None) or song_dict['main_features'].get(feature)\n",
    "        new_song_dict.update({feature:val})\n",
    "    return pd.DataFrame(new_song_dict,index=[0])\n",
    "\n",
    "def get_song(artist_name,song_name):\n",
    "    song_features_dict=get_song_features_and_info_json(song_name=song_name,artist_name=artist_name)\n",
    "    return spotify_preprocessing(song_features_dict)\n",
    "\n",
    "\n",
    "\n",
    "#preprocessing\n",
    "#df=pd.read_pickle('billboard.dat')\n",
    "\n",
    "def cleaning_and_typing(df):    \n",
    "    df.columns=np.arange(df.shape[1])\n",
    "    df['num_words']=df['num_words'].astype(int)\n",
    "    df['num_lines']=df['num_lines'].astype(int)\n",
    "    df['num_dupes']=df['num_dupes'].astype(int)\n",
    "\n",
    "    df['title'].replace(regex=True,to_replace=r\"\\'\",value=r'',inplace=True)\n",
    "    df['artist'].replace(regex=True,to_replace=r\"\\'\",value=r'',inplace=True)\n",
    "    return df\n",
    "    \n",
    "def create_decade_mappings():\n",
    "    all_years=np.arange(1950,2016)\n",
    "    decades=np.arange(1950,2016,10)\n",
    "    decades_mappings={}\n",
    "    cur_dec=decades[0]\n",
    "    cur_dec_idx=0\n",
    "    for year in all_years:\n",
    "        if year%cur_dec>=10:\n",
    "            cur_dec_idx+=1\n",
    "            cur_dec=decades[cur_dec_idx]\n",
    "        decades_mappings.update({year:cur_dec})\n",
    "    return decades_mappings\n",
    "\n",
    "\n",
    "\n",
    "def spotify_preprocessing(song_dict,is_popular=False):\n",
    "    '''\n",
    "        Parsing a *single* song from spotify\n",
    "    '''\n",
    "    #parse dict into df with SPOTIFY_COLUMNS\n",
    "    df = extract_features_from_spotify(song_dict)\n",
    "    \n",
    "    #get year from discgo\n",
    "    discgo_year=get_all_fixed_years(df)[0]\n",
    "    \n",
    "    #add decade\n",
    "    df['year']=df['year'].astype(int)\n",
    "    df['year'] = discgo_year or df['year']\n",
    "    zz=df['year'].map(create_decade_mappings())\n",
    "    zz=zz.fillna(1950)\n",
    "    df.loc[:,'decade']=zz.astype(int)\n",
    "    \n",
    "    #clean artists\n",
    "    df['name'].replace(regex=True,to_replace=r\"\\'\",value=r'',inplace=True)\n",
    "    df['artist'].replace(regex=True,to_replace=r\"\\'\",value=r'',inplace=True)\n",
    "    \n",
    "    #add genre information for each song\n",
    "    df.loc[:,'genre']=df['artist_id'].apply(lambda artist_id:get_genre_of_artist(spotify_client,artist_id))\n",
    "    \n",
    "    #add genre_id\n",
    "    df.loc[:,'genre_id']=df['genre'].apply(lambda x: GENRES.index(x))\n",
    "    \n",
    "    #add popular column\n",
    "    df.loc[:,'popular']=np.int(is_popular)\n",
    "    \n",
    "    #drop year column\n",
    "    df = df.drop('year', 1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot genres (from popular songs)\n",
    "def plot_genres_distribution(popular_songs):\n",
    "    df['popular_songs'].value_counts().plot(kind='bar',title='Genre Popularity',figsize=(12,8))\n",
    "\n",
    "#genres dsitribution\n",
    "def plot_genre_distribution(df):\n",
    "    t=df.groupby(['genre','decade']).count()['artist'].unstack()\n",
    "    sums=t.sum(axis=1).values\n",
    "    t=t.div(sums,axis=0)\n",
    "    ax=t.plot(kind='bar',stacked='True',figsize=(14,8),colormap='PRGn')\n",
    "    ax.set_ylabel('% Songs')\n",
    "    ax.set_xlabel('Genre')\n",
    "    ax.set_title('Genres Distribution over Decades')\n",
    "    ax.legend(bbox_to_anchor=(1.2, 0.5))\n",
    "    \n",
    "\n",
    "#decade songs distribution\n",
    "def plot_decade_distribution(all_songs):\n",
    "    plt.figure()\n",
    "    all_songs.groupby(['decade','popular']).count()['artist'].unstack().plot(kind='bar',figsize=(10,5),title='Decades Songs Distribution')\n",
    "    plt.ylabel('Popularity Distribution')\n",
    "\n",
    "\n",
    "def plot_top_artist_with_hit_songs(all_song,top_art=20):\n",
    "    df=all_songs[all_songs['popular']==1]\n",
    "    df['artist'].value_counts().head(top_art).plot(kind='bar',figsize=(10,5),title='Top {} Aritst with hit songs'.format(top_art))\n",
    "    plt.ylabel('# Hit Songs')\n",
    "    \n",
    "def plot_statistics(df,column,group_by='decade'):\n",
    "    clmns=['mean','std','min','max','25%','50%','75%']\n",
    "    stats=df.groupby(group_by)[column].describe().T\n",
    "    stats = stats.loc[clmns]\n",
    "    ax=stats.plot(kind='box',title='{}'.format(column),figsize=(10,5),rot=90)\n",
    "    ax.set_xlabel(group_by)\n",
    "\n",
    "#PCA\n",
    "def plot_pca_by_decade(df,decade=2000,N=3,colors='popular'):\n",
    "    decade_data = df[df['decade']==decade]\n",
    "    pca_data = decade_data[selected_columns]\n",
    "    #make std=1 and mean=0\n",
    "    pca_data = scale_features(pca_data)\n",
    "    pca = PCA(n_components=N,svd_solver='full')\n",
    "    pca.fit(pca_data)\n",
    "    X_pca = pca.transform(pca_data)\n",
    "    if N < 4:\n",
    "        if colors == 'popular':\n",
    "            clrs = [POPULARITY_COLORS[pop] for pop in decade_data['popular'].values]\n",
    "        if colors == 'genre':\n",
    "            rand_colors=np.random.rand(3,len(GENRES))\n",
    "            clrs = [rand_colors[:,genre_idx] for genre_idx in decade_data['genre_id'].values]\n",
    "\n",
    "        fig=plt.figure(figsize=(8, 5))\n",
    "        if N==3:\n",
    "            ax = Axes3D(fig)\n",
    "            ax.scatter(X_pca[:,0],X_pca[:,1],X_pca[:,2],c=clrs,s=20)\n",
    "        else:\n",
    "            plt.scatter(X_pca[:,0],X_pca[:,1],c=clrs)\n",
    "        plt.title('PCA for decade {}'.format(decade))\n",
    "    print(\"Total Explained Variance for decade {}: {}\".format(decade,np.sum(pca.explained_variance_ratio_)))\n",
    "    return pca\n",
    "    \n",
    "def plot_feature_freq(df,col,decade=1950,ax=None,legend=False):\n",
    "    df = df[df['decade']==decade]\n",
    "    g = sns.kdeplot(df[col][(df[\"popular\"] == 1)], color=\"Blue\", shade = True,ax=ax,legend=False)\n",
    "    sns.kdeplot(df[col][(df[\"popular\"] == 0)], color=\"red\", shade = True,ax=ax,legend=False)\n",
    "    if legend:\n",
    "        g.legend([\"Popular\",\"No Popular\"],fontsize=30)\n",
    "    \n",
    "\n",
    "def plot_grid_kde(df,features,decades):\n",
    "    f, axarr = plt.subplots(len(decades), len(features),figsize=(80,40))\n",
    "    f.subplots_adjust(hspace=0.5, wspace=0.5)\n",
    "    f.text(0.5, 0.04, 'Features', ha='center')\n",
    "    f.suptitle('Features Distribution across Decades')\n",
    "    f.text(0.04, 0.5, 'Decades', va='center', rotation='vertical')\n",
    "    legend=False\n",
    "    for decade_idx,decade in enumerate(decades):\n",
    "        for feature_idx,feature in enumerate(features):\n",
    "            ax = axarr[decade_idx,feature_idx]\n",
    "            if decade_idx==0 and feature_idx==0:\n",
    "                legend=True\n",
    "            else:\n",
    "                legened=False\n",
    "            if feature_idx==0:\n",
    "                ax.set_ylabel(decade,size='50')\n",
    "            if decade_idx == len(decades)-1:\n",
    "                ax.set_xlabel(feature,size='50')\n",
    "            plot_feature_freq(df,col=feature,decade=decade,ax=axarr[decade_idx,feature_idx],legend=legend)\n",
    "    f.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
